{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Correlations and preprocessing\n",
    "\n",
    "Before we start applying machine learning algorithms, we want to have a look at further preprocessing and analyzing steps. To do so, this exercise will mainly deal with scaling, dimensionality reduction, correlation measures and the distribution of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/fifa1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlation vs. causality\n",
    "\n",
    "A common step in data analytics is to investigate correlations between variables. Sometimes these correlations might or might not be derivable from obvious causalities. Create scatter plots of the feature pair 'Ball control' and 'Dribbling' and the feature pair 'Positioning' and 'Penalties'. Do not forget to name the axes of the plots and add suitable titles.\n",
    "\n",
    "In addition, calculate and print the Pearson correlation of each feature pair (you can also add the correlation to the title of the plot for a better overview). For calculation, use for example:\n",
    "\n",
    "https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.pearsonr.html\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.corr.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Make scatter plots, calculate the Pearson correlation, think about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### different correlation measures\n",
    "\n",
    "Beside the Pearson correlation, there are many more correlation measures with different properties. We want to have a closer look at one of them, the so-called Spearman correlation:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient\n",
    "\n",
    "Create a scatter plot of the features 'Overall' and 'Value Euro'. In addition, calculate the Pearson as well as the Spearman correlation of the features. For calculation, use for example:\n",
    "\n",
    "https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.spearmanr.html\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.corr.html\n",
    "\n",
    "##### Questions:\n",
    "\n",
    "Can you give a short explanation of the results? \n",
    "\n",
    "Can you also imagine dependencies between some features that cannot be detected by both correlation measures? Give a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Calculate the correlation measures, make a scatter plot and comment on the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### investigate distributions\n",
    "\n",
    "Create a histogram of the feature *interceptions* using 100 bins and the parameter *normed = True*. In addition, plot a normal distribution with the same mean and variance as line plot into the same diagram (it is recommended to use different colors).\n",
    "For plotting the normal distribution you can use:\n",
    "\n",
    "https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.linspace.html\n",
    "\n",
    "https://docs.scipy.org/doc/scipy-0.16.1/reference/generated/scipy.stats.norm.html\n",
    "\n",
    "What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#TODO: Compute mean and standard deviation, plot both charts in one diagram, what can you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "A common method for dimensionality reduction is the Principal Component Analysis, which is also known from the lecture:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Principal_component_analysis\n",
    "\n",
    "Create scatter plots of the features 'Dribbling' and 'Ball control' before and after applying PCA: \n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "\n",
    "Before doing so, apply z-normalization to both features:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html#sklearn.preprocessing.scale\n",
    "\n",
    "What do you observe? Can you name one advantage and one disadvantage of using PCA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Scale the features, apply pca on them and don't forget to comment on the questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
